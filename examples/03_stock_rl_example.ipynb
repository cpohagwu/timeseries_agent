{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Trading Example\n",
    "\n",
    "This notebook demonstrates using the TimeSeries Agent for stock trading, showing:\n",
    "\n",
    "1. Working with financial data\n",
    "2. Feature engineering for market indicators\n",
    "3. Training an RL agent for directional prediction (Up/Down/Same)\n",
    "4. Real-time trading signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Load .env file\n",
    "from timeseries_agent.api import train_from_csv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_features(df, col_names_dict):\n",
    "    \"\"\"Add technical indicators as features.\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Drop date column\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.drop(columns=col_names_dict['Date'], inplace=True)\n",
    "    \n",
    "    # Price features\n",
    "    df['returns'] = df[col_names_dict['Close']].pct_change()\n",
    "    df['log_returns'] = np.log1p(df['returns'])\n",
    "    \n",
    "    # Moving averages\n",
    "    df['sma_20'] = df[col_names_dict['Close']].rolling(20).mean()\n",
    "    df['sma_50'] = df[col_names_dict['Close']].rolling(50).mean()\n",
    "    df['sma_ratio'] = df['sma_20'] / df['sma_50']\n",
    "    \n",
    "    # Volatility\n",
    "    df['volatility'] = df['returns'].rolling(20).std()\n",
    "    \n",
    "    # Volume features\n",
    "    volume_ma = df[col_names_dict['Volume']].rolling(20).mean()\n",
    "    df['volume_ratio'] = df[col_names_dict['Volume']].div(volume_ma)\n",
    "    \n",
    "    return df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your FMP API key\n",
    "api_key = os.environ.get(\"FMP_API_KEY\")\n",
    "# Symbol to fetch historical data \n",
    "symbol = \"EURUSD\"\n",
    "interval = \"15min\"  # Options: '1min', '5min', '15min', '30min', '1hour', '4hour', '1day', '1week', '1month'\n",
    "\n",
    "# Define the endpoint for historical stock data for NVIDIA\n",
    "url = f'https://financialmodelingprep.com/api/v3/historical-chart/{interval}/{symbol}?apikey={api_key}'\n",
    "\n",
    "# Fetch the data from FMP API\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "# Convert the historical data into a pandas DataFrame\n",
    "data = pd.DataFrame(data)\n",
    "display(data.head())\n",
    "display(data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse the DataFrame to have the most recent data at the top\n",
    "data = data.iloc[::-1].reset_index(drop=True)\n",
    "display(data.head())\n",
    "display(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.a. Add Features Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names_dict = {\n",
    "    'Date': 'date',\n",
    "    'Open': 'open',\n",
    "    'High': 'high',\n",
    "    'Low': 'low',\n",
    "    'Close': 'close',\n",
    "    'Volume': 'volume'\n",
    "}\n",
    "# Add technical indicators as features\n",
    "df = add_features(data, col_names_dict)\n",
    "\n",
    "target_column = 'close'                 # Target column for price prediction\n",
    "df = df.head(1000)                      # Limit to the first 1000 rows for training\n",
    "# Save test data except the last n rows\n",
    "last_n_test_rows = 100\n",
    "train_data = df.iloc[:-last_n_test_rows]\n",
    "test_data = df.tail(last_n_test_rows)\n",
    "\n",
    "\n",
    "# Save train data\n",
    "print(f\"Train Shape: {train_data.shape}, Test Shape: {test_data.shape}\")\n",
    "display(train_data.head())\n",
    "display(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot stock price/train and test data\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.plot(train_data.index, train_data['close'], color='blue', label='Train Close Price')\n",
    "plt.plot(test_data.index, test_data['close'], color='orange', label='Test Close Price')\n",
    "plt.scatter(train_data.index, train_data['close'], color='blue', s=10, alpha=0.5)\n",
    "plt.scatter(test_data.index, test_data['close'], color='orange', s=10, alpha=0.5)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price')\n",
    "plt.title(f\"{symbol} Price Data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b. Compute Target Direction Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distribution of directions\n",
    "train_target_diff = train_data[target_column].diff()\n",
    "train_directions = train_target_diff.apply(lambda x: 0 if x > 0 else 1 if x < 0 else 2).iloc[1:]\n",
    "train_directions_counts = Counter(train_directions)\n",
    "print(\"Train Directions Counts:\", train_directions_counts)\n",
    "\n",
    "test_target_diff = test_data[target_column].diff()\n",
    "test_directions = test_target_diff.apply(lambda x: 0 if x > 0 else 1 if x < 0 else 2).iloc[1:]\n",
    "test_directions_counts = Counter(test_directions)\n",
    "print(\"Test Directions Counts:\", test_directions_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the a bar plot for the distribution of directions\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=list(train_directions_counts.keys()), y=list(train_directions_counts.values()), color='blue', alpha=0.6, label='Train')\n",
    "sns.barplot(x=list(test_directions_counts.keys()), y=list(test_directions_counts.values()), color='orange', alpha=0.6, label='Test')\n",
    "plt.xlabel('Direction')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Directions in Train and Test Data')\n",
    "plt.xticks([0, 1, 2], ['Up', 'Down', 'No Change'])\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training and testing data to CSV files\n",
    "DATA_DIR = 'data'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "train_csv_path = os.path.join(DATA_DIR, 'fin_train.csv')\n",
    "test_csv_path = os.path.join(DATA_DIR, 'fin_test.csv')\n",
    "\n",
    "train_data.to_csv(train_csv_path, index=False)\n",
    "test_data.to_csv(test_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Reward Strategy\n",
    "\n",
    "The agent automatically calculates rewards during training based on:\n",
    "- Action 0: Predict price will go Up\n",
    "- Action 1: Predict price will go Down  \n",
    "- Action 2: Predict price will stay Same\n",
    "\n",
    "Reward is +1 for correct predictions, -1 for incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_config = {\n",
    "    'method': 'proportional',\n",
    "    'scale': 100.0,                # Amplify small returns\n",
    "    'min_change_pct': 0.001        # Min 0.1% move for reward. This helps avoid noise and serves as a bid/ask spread filter\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "feature_cols = [\n",
    "    'returns', 'sma_ratio', 'volatility',\n",
    "    'volume_ratio', 'log_returns'\n",
    "    ] + [target_column]\n",
    "\n",
    "# Define environment kwargs\n",
    "lookback = 10\n",
    "env_kwargs = {\n",
    "        'lookback': lookback,\n",
    "        'normalize_state': True,\n",
    "        'test_size': 0.2                    # Use 20% of data for validation\n",
    "    }\n",
    "\n",
    "# Define agent kwargs \n",
    "agent_type = 'ppo'                          # options: 'ppo', 'reinforce', and 'reinforce_step'\n",
    "agent_kwargs = {\n",
    "        'hidden_layers': [64, 32],          # More complex architecture for better learning\n",
    "        'output_size': 3,                   # Three possible actions: Up, Down, Same\n",
    "        'agent_type': agent_type,  \n",
    "    }\n",
    "\n",
    "# Define trainer kwargs\n",
    "trainer_kwargs = {\n",
    "        'max_epochs': 100,\n",
    "        'enable_checkpointing': True,\n",
    "        'experiment_name': f'{symbol}_trading'\n",
    "    }\n",
    "\n",
    "# Train with automatic action sampling and reward generation\n",
    "agent = train_from_csv(\n",
    "    csv_path=train_csv_path,\n",
    "    feature_cols=feature_cols,\n",
    "    target_col=target_column,\n",
    "    reward_config=reward_config,\n",
    "    env_kwargs=env_kwargs,\n",
    "    agent_kwargs=agent_kwargs,\n",
    "    trainer_kwargs=trainer_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.a. Plot Training Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeseries_agent.utils.extras import plot_training_metrics\n",
    "plot_training_metrics(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate Agent\n",
    "The agent predicts market direction (Up/Down/Same) based on recent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeseries_agent.api import load_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = agent.trainer.logger.log_dir\n",
    "checkpoint_path = os.path.join(log_dir, 'checkpoints', 'last.ckpt')\n",
    "print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained agent\n",
    "loaded_agent = load_agent(\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    csv_path=test_csv_path,\n",
    "    feature_cols=feature_cols,\n",
    "    target_col=target_column,\n",
    "    agent_type=agent_type,              # Specify the agent type\n",
    "    **env_kwargs                        # Pass the same environment configuration used during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_profit_loss(current_val, next_val, true_action, pred_action):\n",
    "    \"\"\"\n",
    "    Calculate the profit or loss based on price change and action taken,\n",
    "    considering pip_value as the cost of trade.\n",
    "    \"\"\"\n",
    "    pip_value = 0.0001  # For forex pairs like AUDUSD, pip value is typically 0.0001\n",
    "    diff = (next_val - current_val)\n",
    "    profit_loss = 0.0\n",
    "\n",
    "    if pred_action == 2:\n",
    "        # No action taken, return 0\n",
    "        profit_loss = 0.0\n",
    "    elif true_action == pred_action:\n",
    "        # Correct prediction\n",
    "        if abs(diff) > 0:\n",
    "            profit_loss = abs(diff) - pip_value # abs(diff) because the action was correct and we want profit\n",
    "    return profit_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_action(current_val, next_val):\n",
    "    true_action = 0 if next_val > current_val else 1 if next_val < current_val else 2\n",
    "    return true_action\n",
    "\n",
    "# Batch predictions on historical data\n",
    "def get_batch_predictions(df, lookback_size):\n",
    "    predictions = []\n",
    "    true_actions = []\n",
    "    total_profit = 0.0\n",
    "    for i in range(lookback_size, len(df)):\n",
    "        if i >= len(df) - 1:\n",
    "            continue\n",
    "        current_features = df[feature_cols].iloc[i-lookback_size:i].values.astype(np.float32)\n",
    "        current_target = df[target_column].iloc[i]\n",
    "        pred_action, probs = loaded_agent.act(current_features, return_probs=True)\n",
    "        predictions.append(pred_action)\n",
    "        next_target = df[target_column].iloc[i+1]\n",
    "        true_action = get_true_action(current_target, next_target)\n",
    "        pl = get_profit_loss(current_target, next_target, true_action, pred_action)\n",
    "        total_profit += pl\n",
    "        message = f'Profit={pl:.4f}' if pl > 0 else f'Loss={pl:.4f}'\n",
    "        print(f'True={true_action} -- Pred={pred_action} -- Prob={probs} -- {message}')\n",
    "        true_actions.append(true_action)\n",
    "        \n",
    "    return true_actions, predictions, total_profit\n",
    "\n",
    "# Get predictions\n",
    "df = pd.read_csv(test_csv_path)\n",
    "y_true, y_pred, total_profit = get_batch_predictions(df[:], lookback)\n",
    "\n",
    "print(f'\\n true dist == {Counter(y_true)}, pred dist == {Counter(y_pred)}')\n",
    "print(f'Total Profit/Loss: {total_profit:.4f} pips')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.a. Visualize Agents Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeseries_agent.utils.extras import plot_prediction_density, plot_confusion_matrix_n_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_density(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_n_metrics(y_true, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
