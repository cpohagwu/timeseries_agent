{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Synthetic Dataset Example\n",
    "\n",
    "This notebook demonstrates using the TimeSeries Agent for a benchmark synthetic dataset, showing:\n",
    "\n",
    "1. Working with synthetic data\n",
    "2. Training an RL agent for directional prediction (Up/Down/Same)\n",
    "3. Evaluating the agent's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from timeseries_agent.api import train_from_csv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/datasets/global-temp/main/data/monthly.csv\")\n",
    "df = df[df['Source'] == 'gcag']\n",
    "df = df[['Year', 'Mean']]\n",
    "df['temperature'] = df['Mean']\n",
    "df.drop(columns=['Mean'], inplace=True)\n",
    "print(df.shape)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'temperature'\n",
    "df = df.head(1000)  # Limit to the first 1000 rows for training\n",
    "last_n_test_rows = 100 # Number of rows to keep for testing\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = df.iloc[:-last_n_test_rows]\n",
    "test_data = df.tail(last_n_test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the training and testing data\n",
    "plt.figure(figsize=(18, 6))\n",
    "plt.plot(train_data.index, train_data[target_column], color='blue', label='Train Value')\n",
    "plt.plot(test_data.index, test_data[target_column], color='orange', label='Test Value')\n",
    "plt.scatter(train_data.index, train_data[target_column], color='blue', s=10, alpha=0.5)\n",
    "plt.scatter(test_data.index, test_data[target_column], color='orange', s=10, alpha=0.5)\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel(target_column)\n",
    "plt.title(f\"{target_column} Over Time Steps (Train and Test Data)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute distribution of directions\n",
    "train_target_diff = train_data[target_column].diff()\n",
    "train_directions = train_target_diff.apply(lambda x: 0 if x > 0 else 1 if x < 0 else 2).iloc[1:]\n",
    "train_directions_counts = Counter(train_directions)\n",
    "print(\"Train Directions Counts:\", train_directions_counts)\n",
    "\n",
    "test_target_diff = test_data[target_column].diff()\n",
    "test_directions = test_target_diff.apply(lambda x: 0 if x > 0 else 1 if x < 0 else 2).iloc[1:]\n",
    "test_directions_counts = Counter(test_directions)\n",
    "print(\"Test Directions Counts:\", test_directions_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the a bar plot for the distribution of directions\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=list(train_directions_counts.keys()), y=list(train_directions_counts.values()), color='blue', alpha=0.6, label='Train')\n",
    "sns.barplot(x=list(test_directions_counts.keys()), y=list(test_directions_counts.values()), color='orange', alpha=0.6, label='Test')\n",
    "plt.xlabel('Direction')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Directions in Train and Test Data')\n",
    "plt.xticks([0, 1, 2], ['Up', 'Down', 'No Change'])\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract lags from the target column\n",
    "train_data['Lag1'] = train_data[target_column].shift(1)\n",
    "train_data['Lag2'] = train_data[target_column].shift(2)\n",
    "test_data['Lag1'] = test_data[target_column].shift(1)\n",
    "test_data['Lag2'] = test_data[target_column].shift(2)\n",
    "\n",
    "# Drop rows with NaN values after shifting\n",
    "train_data = train_data.dropna(subset=['Lag1', 'Lag2'])\n",
    "test_data = test_data.dropna(subset=['Lag1', 'Lag2'])\n",
    "\n",
    "print(f\"Train Shape: {train_data.shape}, Test Shape: {test_data.shape}\")\n",
    "display(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the training and testing data to CSV files\n",
    "DATA_DIR = 'data'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "train_csv_path = os.path.join(DATA_DIR, 'global_temp_train.csv')\n",
    "test_csv_path = os.path.join(DATA_DIR, 'global_temp_test.csv')\n",
    "\n",
    "train_data.to_csv(train_csv_path, index=False)\n",
    "test_data.to_csv(test_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns and target column. Note: Target column can also be used as a feature\n",
    "feature_cols = ['Lag1', 'Lag2']  + [target_column]  \n",
    "target_col= target_column \n",
    "\n",
    "# Define environment kwargs\n",
    "lookback = 10                                           # Number of previous time steps to consider  \n",
    "env_kwargs = {\n",
    "        'lookback': lookback,\n",
    "        'normalize_state': True,\n",
    "        'test_size': 0.2                                # Use 20% of data for validation\n",
    "    }\n",
    "\n",
    "# Define agent kwargs \n",
    "agent_type = 'reinforce_step'                           # options: 'ppo', 'reinforce', and 'reinforce_step'\n",
    "agent_kwargs = {\n",
    "        'hidden_layers': [100, 100, 10],                # More complex architecture for better learning\n",
    "        'output_size': 3,                               # Three possible actions: Up, Down, Same\n",
    "        'agent_type': agent_type,\n",
    "    }\n",
    "\n",
    "# Define trainer kwargs\n",
    "trainer_kwargs = {\n",
    "        'max_epochs': 100,                               # Number of epochs for training\n",
    "        'enable_checkpointing': True,\n",
    "        'experiment_name': f'pattern_bm_{agent_type}',   # Name of the experiment\n",
    "    }\n",
    "\n",
    "# Train with automatic action sampling and reward generation\n",
    "agent = train_from_csv(\n",
    "    csv_path=train_csv_path,\n",
    "    feature_cols=feature_cols,\n",
    "    target_col=target_col,\n",
    "    env_kwargs=env_kwargs,\n",
    "    agent_kwargs=agent_kwargs,\n",
    "    trainer_kwargs=trainer_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. a. Plot Training Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeseries_agent.utils.extras import plot_training_metrics\n",
    "plot_training_metrics(agent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate Agent\n",
    "\n",
    "The agent predicts the direction of the sequence (Up/Down/Same) based on recent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeseries_agent.api import load_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = agent.trainer.logger.log_dir\n",
    "checkpoint_path = os.path.join(log_dir, 'checkpoints', 'last.ckpt')\n",
    "print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained agent\n",
    "loaded_agent = load_agent(\n",
    "    checkpoint_path=checkpoint_path,\n",
    "    csv_path=test_csv_path,\n",
    "    feature_cols=feature_cols,\n",
    "    target_col=target_col,\n",
    "    agent_type=agent_type,                  # Specify the agent type\n",
    "    **env_kwargs                            # Pass the same environment configuration used during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0: Up, 1: Down, 2: Same\n",
    "def get_true_action(current_val, next_val):\n",
    "    true_action = 0 if next_val > current_val else 1 if next_val < current_val else 2\n",
    "    return true_action\n",
    "\n",
    "# Batch predictions on historical data\n",
    "def get_batch_predictions(df, lookback_size):\n",
    "    predictions = []\n",
    "    true_actions = []\n",
    "    for i in range(lookback_size, len(df)):\n",
    "        if i >= len(df) - 1:\n",
    "            continue\n",
    "        current_features = df[feature_cols].iloc[i-lookback_size:i].values.astype(np.float32)\n",
    "        current_target = df[target_col].iloc[i]\n",
    "        pred_action, probs = loaded_agent.act(current_features, return_probs=True)\n",
    "        predictions.append(pred_action)\n",
    "        next_target = df[target_col].iloc[i+1]\n",
    "        true_action = get_true_action(current_target, next_target)\n",
    "        print(f'True={true_action} -- Pred={pred_action} -- Probs={probs}')\n",
    "        true_actions.append(true_action)\n",
    "        \n",
    "    return true_actions, predictions\n",
    "\n",
    "# Load the test data and get predictions\n",
    "df = pd.read_csv(test_csv_path)\n",
    "\n",
    "lookback_size = lookback\n",
    "y_true, y_pred = get_batch_predictions(df[:], lookback_size)\n",
    "\n",
    "print(f'\\n true dist == {Counter(y_true)}, pred dist == {Counter(y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.b. Visualize Agents Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeseries_agent.utils.extras import (plot_prediction_density, \n",
    "                            plot_confusion_matrix_n_metrics, plot_animated_signal_line_chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction_density(y_true, y_pred,\n",
    "                        os.path.join(DATA_DIR,'predictions_analysis.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix_n_metrics(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_animated_signal_line_chart(df, target_column, y_true, y_pred, lookback,\n",
    "                                os.path.join(DATA_DIR,'global_temp_predictions_animation.gif'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tests",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
